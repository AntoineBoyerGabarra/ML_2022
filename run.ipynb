{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7f71033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d43d4",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61ee2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data \n",
    "def load_csv_data(data_path, sub_sample=False):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int)\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y == \"b\")] = -1\n",
    "\n",
    "    # sub-sample\n",
    "    if sub_sample:\n",
    "        yb = yb[::50]\n",
    "        input_data = input_data[::50]\n",
    "        ids = ids[::50]\n",
    "\n",
    "    return yb, input_data, ids\n",
    "\n",
    "def cleanning(data):\n",
    "    toDelete = []\n",
    "    \n",
    "    \n",
    "                \n",
    "    mean = np.mean(data, axis=0)\n",
    "    var = np.var(data, axis=0)\n",
    "    taille = len(data)\n",
    "    taille2 = len(data[0])\n",
    "    \n",
    "    for i in range(taille):\n",
    "        for j in range(taille2):\n",
    "            if(data[i][j] == -999.0):\n",
    "                toDelete = toDelete + [j]\n",
    "                \n",
    "    return np.delete(data, toDelete, axis=1), toDelete\n",
    "\n",
    "#standardize the data\n",
    "def standardize(x):\n",
    "\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    \n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x\n",
    "\n",
    "#create a csv submission\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})\n",
    "            \n",
    "#Cross-validation implementation\n",
    "\n",
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "    \n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c41595dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 2. 4. 2. 7. 7. 7. 7.]\n",
      " [3. 2. 4. 2. 7. 7. 7. 7.]\n",
      " [3. 2. 4. 2. 7. 7. 7. 7.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[3.0,2.0,4.0,5.0,7.0,7.0,7.0,7.0],[3.0,2.0,4.0,5.0,7.0,7.0,7.0,7.0],[3.0,2.0,4.0,5.0,7.0,7.0,7.0,7.0]])\n",
    "\n",
    "((x[:,3])[x[:,3] == 5]) = 2\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a5f0b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43521/851914117.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ids = x[:, 0].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_csv_data('train.csv', sub_sample=True)\n",
    "#test_data = load_csv_data('test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "51d04b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 30)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1ff0a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[4] is ut of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3effec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, mean_x, std_x = standardize(train_data[1])\n",
    "# 1st column is 'y'\n",
    "# 2nd column is 'X'\n",
    "# 3rd column is 'ids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d67718a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cleanning() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43521/2364750222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data_cleanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data_std1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_cleanned\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#see to what it corresponds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train_data_std2, mean2, std2 = standardize(train_data[2]) #see to what it corresponds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cleanning() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "train_data_cleanned, y_clean = cleanning(train_data[1], train_data[0])\n",
    "train_data_std1, mean1, std1 = standardize(train_data_cleanned) #see to what it corresponds\n",
    "#train_data_std2, mean2, std2 = standardize(train_data[2]) #see to what it corresponds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "47d5dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model_data(height, weight):   \n",
    "    \n",
    "    y = weight\n",
    "    x = height\n",
    "    num_samples = len(y)\n",
    "    tx = np.c_[np.ones(num_samples), x]\n",
    "    return y, tx\n",
    "\n",
    "\n",
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1a18b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multi_Model(y, tx, initial_w, max_iters, gamma):\n",
    "    tx0 = []\n",
    "    tx1 = []\n",
    "    tx2 = []\n",
    "    tx3 = []\n",
    "    taille = len(tx)\n",
    "    for i in range(taille):\n",
    "        if(tx[i][22]==0):\n",
    "            tx0 = tx0 + [tx[i]]\n",
    "        else:\n",
    "            if(tx[i][22]==1):\n",
    "                tx1 = tx1 + [tx[i]]\n",
    "            else:\n",
    "                if(tx[i][22]==2):\n",
    "                    tx2 = tx2 + [tx[i]]\n",
    "                else:\n",
    "                    if(tx[i][22]==3):\n",
    "                        tx3 = tx3 + [tx[i]]\n",
    "    \n",
    "    return np.array(tx0), np.array(tx1), np.array(tx2), np.array(tx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7320497a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195520, 30)\n",
      "(1985, 30)\n",
      "(1540, 30)\n",
      "(1043, 30)\n",
      "(432, 30)\n"
     ]
    }
   ],
   "source": [
    "tx0, tx1, tx2, tx3 = Multi_Model(y, train_data[1], np.ones(len(tx[0])), 10000, 0.2)\n",
    "print(train_data_cleanned.shape)\n",
    "print(np.array(tx0).shape)\n",
    "print(np.array(tx1).shape)\n",
    "print(np.array(tx2).shape)\n",
    "print(np.array(tx3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9cd6b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx0_bis, y_clean1 = cleanning(tx0)\n",
    "tx1_bis, y_clean2 = cleanning(tx1)\n",
    "tx2_bis, y_clean3 = cleanning(tx2)\n",
    "tx3_bis, y_clean4 = cleanning(tx3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb3af1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1985, 19)\n",
      "(1540, 22)\n",
      "(1043, 29)\n",
      "(432, 29)\n"
     ]
    }
   ],
   "source": [
    "print(tx0_bis.shape)\n",
    "print(tx1_bis.shape)\n",
    "print(tx2_bis.shape)\n",
    "print(tx3_bis.shape)\n",
    "\n",
    "y_clean = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de30a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1985, 20)\n",
      "[1.]\n",
      "[0.5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (20,1985) and (195520,1985) not aligned: 1985 (dim 1) != 195520 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43521/2036935200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ML_2022/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# previously calculate_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# previously calculate_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ML_2022/implementations.py\u001b[0m in \u001b[0;36mc_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;34m\"\"\"gradient of logistic regression\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (20,1985) and (195520,1985) not aligned: 1985 (dim 1) != 195520 (dim 0)"
     ]
    }
   ],
   "source": [
    "import implementations\n",
    "\n",
    "_, tx = build_model_data(tx0_bis, tx0_bis)\n",
    "\n",
    "print(tx.shape)\n",
    "\n",
    "#_, tc = build_model_data(test_data[1], test_data[1])\n",
    "\n",
    "y = (y_clean + 1)/2\n",
    "\n",
    "print(max(y))\n",
    "print(min(y))\n",
    "    \n",
    "loss, w = implementations.logistic_regression(y, tx, np.ones(len(tx[0])), 10000, 0.2)\n",
    "print()\n",
    "loss1, w1 = implementations.reg_logistic_regression(y, tx, 1, np.ones(len(tx[0])), 10000, 0.2)\n",
    "print()\n",
    "loss2, w2 = implementations.mean_squared_error_gd(y, tx, np.ones(len(tx[0])), 10000, 0.02)\n",
    "print()\n",
    "loss3, w3 = implementations.mean_squared_error_sgd(y, tx, np.ones(len(tx[0])), 10000, 0.002)\n",
    "print()\n",
    "w4, mse = implementations.least_squares(y, tx)\n",
    "print(\"ok\")\n",
    "w5, mse = implementations.ridge_regression(y, tx, 0.03)\n",
    "\n",
    "#form K subgroups randomly\n",
    "k_fold = 10\n",
    "seed = 0\n",
    "k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "#Pattern with method\n",
    "rmse_tr_tmp = []\n",
    "rmse_te_tmp = []\n",
    "w_tr_tmp = []\n",
    "w_te_tmp = []\n",
    "for k in range(k_fold):\n",
    "    # Put the kth group in test\n",
    "    te_indice = k_indices[k]\n",
    "    tr_indice = k_indices[~(np.arange(k_indices.shape[0]) == k)]\n",
    "    tr_indice = tr_indice.reshape(-1)\n",
    "    y_te = y[te_indice]\n",
    "    y_tr = y[tr_indice]\n",
    "    x_te = tx[te_indice]\n",
    "    x_tr = tx[tr_indice]\n",
    "    loss_tr, w_tr = implementations.logistic_regression(y_tr, x_tr, np.ones(len(x_tr[0])), 10000, 0.2)\n",
    "    loss_te, w_te = implementations.logistic_regression(y_te, x_te, np.ones(len(x_te[0])), 10000, 0.2)\n",
    "    rmse_tr_tmp.append(loss_tr)\n",
    "    rmse_te_tmp.append(loss_te)\n",
    "    w_tr_tmp.append(w_tr)\n",
    "    w_te_tmp.append(w_te)\n",
    "rmse_tr = np.mean(rmse_tr_tmp, axis=0)\n",
    "rmse_te = np.mean(rmse_te_tmp, axis=0)\n",
    "wTR = np.mean(w_tr_tmp, axis=0)\n",
    "wTE = np.mean(w_te_tmp, axis=0)\n",
    "\n",
    "    \n",
    "    \n",
    "predi = implementations.sigmoid(tx @ w)\n",
    "predi_t = np.sign(predi - 0.5)\n",
    "\n",
    "predi1 = implementations.sigmoid(tx @ w1)\n",
    "predi_t1 = np.sign(predi1 - 0.5)\n",
    "\n",
    "predi2 = tx @ w2\n",
    "predi_t2 = np.sign(predi2 - 0.5)\n",
    "\n",
    "predi3 = tx @ w3\n",
    "predi_t3 = np.sign(predi3 - 0.5)\n",
    "\n",
    "predi4 = tx @ w4\n",
    "predi_t4 = np.sign(predi4 - 0.5)\n",
    "\n",
    "predi5 = tx @ w5\n",
    "predi_t5 = np.sign(predi5 - 0.5)\n",
    "\n",
    "predi6 = tx @ wTR\n",
    "predi_t6 = np.sign(predi6 - 0.5)\n",
    "\n",
    "predi7 = tx @ wTE\n",
    "predi_t7 = np.sign(predi7 - 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8824d15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 285. GiB for an array with shape (195520, 195520) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43521/121915389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(tx.shape, y.shape, w.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplementations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression_newton_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ML_2022/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression_newton_method\u001b[0;34m(y, tx, lambda_, initial_w, max_iter, gamma)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_newton_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m# log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m#if iter % 1 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ML_2022/implementations.py\u001b[0m in \u001b[0;36mlearning_by_newton_method\u001b[0;34m(y, tx, w, gamma)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \"\"\"\n\u001b[1;32m    206\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mhessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_hessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/ML_2022/implementations.py\u001b[0m in \u001b[0;36mc_hessian\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 285. GiB for an array with shape (195520, 195520) and data type float64"
     ]
    }
   ],
   "source": [
    "#test Newton\n",
    "import implementations\n",
    "\n",
    "#careful about the dimensions of y and w! (N/D,1) instead of (N/D,)!\n",
    "\n",
    "_, tx = build_model_data(train_data_std1, train_data_std1)\n",
    "w = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "y = np.array([(y_clean + 1)/2]).T\n",
    "\n",
    "#print(tx.shape, y.shape, w.shape)\n",
    "\n",
    "loss8, w8 = implementations.logistic_regression_newton_method(y, tx, 0.1, w, 100, 1)\n",
    "print(loss8, w8)\n",
    "\n",
    "predi8 = tx @ w8\n",
    "predi_t8 = np.sign(predi8 - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285c763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t)):\n",
    "    if(predi_t[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 0 : \" + str(1 - test/len(predi_t)))\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t1)):\n",
    "    if(predi_t1[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 1 : \" + str(1 - test/len(predi_t1)))\n",
    "\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t2)):\n",
    "    if(predi_t2[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 2 : \" + str(1 - test/len(predi_t2)))\n",
    "\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t3)):\n",
    "    if(predi_t3[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 3 : \" + str(1 - test/len(predi_t3)))\n",
    "\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t4)):\n",
    "    if(predi_t4[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 4 : \" + str(1 - test/len(predi_t4)))\n",
    "\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t5)):\n",
    "    if(predi_t5[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 5 : \" + str(1 - test/len(predi_t5)))\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t6)):\n",
    "    if(predi_t6[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 6 : \" + str(1 - test/len(predi_t6)))\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t7)):\n",
    "    if(predi_t7[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 7 : \" + str(1 - test/len(predi_t7)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = 0\n",
    "\n",
    "for i in range(len(predi_t8)):\n",
    "    if(predi_t8[i] != y_clean[i]):\n",
    "        test += 1\n",
    "\n",
    "print(\"test 8 : \" + str(1 - test/len(predi_t8)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
